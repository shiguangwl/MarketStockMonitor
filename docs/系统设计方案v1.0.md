好的，非常理解您对“代码可控性”的偏好。放弃基于配置的自动装配，转而采用在启动时以代码明确构建对象关系的方式，可以让数据流和依赖关系更加清晰直观。

同时，将“开收盘时间动态化”作为核心需求，我们需要对 `DataSourceManager` 的设计进行深化，使其从一个被动查询的服务，变为一个具备主动更新能力的状态管理器。

以下是根据您的新要求和我们之前探讨的设计模式，优化后的一个全新的、完整的系统设计方案。

-----

### **股票/指数数据抓取通知服务 - 系统设计方案 (V2)**

#### 1\. 系统愿景与设计原则

**愿景**: 构建一个基于 Python 异步生态、以显式代码构建服务关系、处理流程高度可定制、稳定可靠的金融数据服务。

**核心设计原则**:

  * **异步优先 (Async-First)**: 核心I/O操作（数据抓取、API调用、数据库、消息推送）均采用 `async/await`，最大化系统吞吐量。
  * **策略驱动 (Strategy-Driven)**: 系统的可变部分（如何抓取、如何判断交易时间）由具体的策略类实现，易于扩展和替换。
  * **组合优于继承 (Composition over Inheritance)**: 通过将小型、单一职责的组件（如处理链中的处理器）组合起来，构建复杂的业务逻辑，而不是依赖深层次的继承。
  * **显式依赖注入 (Explicit Dependency Injection)**: 在系统启动入口 (`main.py`)，显式地创建服务实例并注入其依赖，使得服务间的关系一目了然，易于追踪和测试。
  * **类型注解 (Type-Hinted)**: 全面使用 Python 类型提示和 Pydantic，确保数据在系统内部流转时的类型安全和结构正确性。

#### 2\. 技术栈选型

  * **Web 框架**: **FastAPI**
  * **异步 HTTP 客户端**: **HTTPX**
  * **数据结构与校验**: **Pydantic**
  * **定时任务**: **APScheduler (AsyncIOScheduler)**
  * **日志**: **Loguru**
  * **数据库 (用于DLQ)**: **MySQL** + **SQLAlchemy (Asyncio Extension)**
  * **SSE 推送**: **sse-starlette**

#### 3\. 系统核心架构

系统架构围绕两大核心流程进行：**周期性的规则更新**和**高频的数据处理**。

1.  **规则更新流程 (低频、定时)**: `交易时间管理器` 定时触发 `交易时间策略`，令其从外部数据源抓取最新的节假日和交易规则，并缓存于内存中。
2.  **数据处理流程 (高频、实时)**: `数据获取引擎` 在每次抓取前，向 `交易时间管理器` 查询市场状态。若开市，则启动抓取，并将获取到的数据送入一个由多个处理器组成的 `数据处理管道`。

**数据流**: `数据获取引擎 (Fetcher)` -\> `数据处理管道 (Processing Pipeline)`


#### 4\. 模块详细设计

##### 4.1 交易时间管理器 (Trading Hours Manager)

  * **职责**: 系统的“时间中枢”。主动、周期性地获取并管理各个市场的交易时间规则，并对外提供权威的市场状态查询。
  * **核心组件/接口定义**:
      * **`ITradingHoursProvider` (ABC)**: 定义交易时间策略的契约。
          * `async def refresh_rules(self) -> None`: **(核心新增)** 核心方法。实现此方法的代码需要通过API或爬虫等方式，获取最新的常规交易时段和特殊休市安排（如节假日），并更新到自身状态中。
          * `async def get_market_status(self, check_time: datetime) -> MarketStatus`: 根据内部缓存的最新规则，判断给定时间的市场状态。
      * **`TradingHoursManager` (服务类)**:
          * 内部维护一个从 `source_id` 到 `ITradingHoursProvider` 实例的映射。
          * 提供 `register_provider` 方法。
          * **提供 `schedule_all_refreshes(self, scheduler: AsyncIOScheduler)` 方法**: 在系统启动时调用，为每一个已注册的 `Provider` 创建一个定时任务（例如每天凌晨执行一次），调用其 `refresh_rules` 方法。
          * 提供 `async def get_status(self, source_id: str) -> MarketStatus` 对外查询接口。

##### 4.2 数据获取引擎 (Data Fetching Engine) - [采用模板方法模式]

  * **职责**: 数据的生产者。根据具体策略，高效、稳定地从外部数据源抓取数据，并通知下游处理。
  * **核心组件/接口定义**:
      * **`IFetcherStrategy` (ABC)**: 定义数据获取策略的顶层契约。
          * `async def start(self)` / `async def stop(self)`
          * `add_observer(self, observer)` / `notify(self, data)` (观察者模式)
      * **`AbstractFetcher` (ABC, 继承 `IFetcherStrategy`)**:
          * 实现了观察者模式的具体逻辑。
          * 实现了 `start` 方法，内部包含一个循环，每次循环前会检查市场状态。
          * **实现 `fetch_and_process_data(self) -> list[MarketData]` (模板方法)**:
              * 这是一个**具体方法**，它定义了抓取、解析、转换的标准流程。
              * 它会依次调用下列由子类实现的“钩子”方法。
          * **`_build_request_details(self) -> tuple[str, dict]` (抽象钩子方法)**: 子类实现，返回请求的URL和参数。
          * **`_parse_response(self, response_body: bytes) -> any` (抽象钩子方法)**: 子类实现，负责解析原始响应体。
          * **`_transform_to_marketdata(self, parsed_data: any) -> list[MarketData]` (抽象钩子方法)**: 子类实现，将解析后的数据转换为标准的 `MarketData` 列表。

##### 4.3 数据处理管道 (Data Processing Pipeline) - [采用责任链模式]

  * **职责**: 数据的消费者和处理器。将数据处理流程分解为一系列可独立重用、可自由组合的步骤。
  * **核心组件/接口定义**:
      * **`IProcessingHandler` (ABC)**: 定义处理节点的契约。
          * `set_next(self, handler: 'IProcessingHandler') -> 'IProcessingHandler'`: 用于构建链条，并返回下一个处理器以便链式调用。
          * `async def handle(self, data: MarketData) -> None`: 处理数据的核心方法。
      * **`AbstractProcessingHandler` (ABC, 继承 `IProcessingHandler`)**:
          * 实现了 `set_next` 和一个通用的 `handle` 方法。
          * 通用的 `handle` 方法会先调用一个由子类实现的 `_process` 方法，然后检查 `next_handler` 是否存在，若存在则继续传递。
          * `async def _process(self, data: MarketData) -> bool`: 子类实现的具体处理逻辑，返回 `True` 表示继续传递，`False` 表示终止链条。
      * **具体 Handler 实现**:
          * `KlineConsolidationHandler`: 判断 `MarketData` 的时间戳是否满足特定K线周期（如15分钟），不满足则终止链条。
          * `WebhookDispatchHandler`: 调用 `RetryableTaskExecutor` 向指定URL发送Webhook。通常作为链的末端。
          * `SseDispatchHandler`: 将数据推送给所有SSE连接的客户端。通常作为链的末端。
          * `ConsoleLogHandler`: 打印数据到控制台，用于调试。

##### 4.4 健壮性保障模块 (Robustness Assurance Module)

  * **职责**: 为关键的、不可失败的任务（如Webhook推送）提供重试和持久化能力。
  * **设计**: (此模块设计已非常完善，保持不变)
      * **`RetryableTaskExecutor`**: 提供带指数退避重试逻辑的异步任务执行器。
      * **`DeadLetterQueue`**: 当重试耗尽后，将失败任务的信息（目标、载荷、错误原因）存入数据库，以备后续人工排查或重试。

#### 5\. 核心工作流

1.  **系统启动 (`main.py`)**:

      * 实例化 `TradingHoursManager`, `APScheduler`。
      * **显式创建**具体的 `ITradingHoursProvider` 实例（如 `CNStockHoursProvider`），并**注册**到 `TradingHoursManager` 中。
      * 调用 `trading_manager.schedule_all_refreshes(scheduler)`，创建规则更新的定时任务。
      * **显式创建**具体的 `AbstractFetcher` 实例（如 `SinaStockFetcher`）。
      * **显式创建并链接**处理链：
        `pipeline_head = KlineConsolidationHandler()`
        `webhook_handler = WebhookDispatchHandler(retry_executor)`
        `pipeline_head.set_next(webhook_handler)`
      * 将 `pipeline_head` 作为观察者**注册**到 `Fetcher` 实例中。
      * 启动 `APScheduler` 和 `FastAPI` 应用。
      * 调用 `fetcher.start()` 启动数据抓取循环。

2.  **运行时**:

      * `APScheduler` 在凌晨触发 `CNStockHoursProvider.refresh_rules()`，后者从交易所网站或API获取最新节假日安排，更新内存缓存。
      * `SinaStockFetcher` 的循环运行，每次都向 `TradingHoursManager` 查询A股市场状态。
      * 若开市，`fetcher` 调用自身的 `fetch_and_process_data` 模板方法，通过 `_build_request_details` 等钩子方法获取到 `MarketData`。
      * `fetcher` 调用 `notify()`，进而触发 `pipeline_head.handle(data)`。
      * 数据在责任链中流转：先经过 `KlineConsolidationHandler` 判断时间，若满足条件，则传递给 `WebhookDispatchHandler`，后者使用 `RetryableTaskExecutor` 异步发送通知。

#### 6\. 开发计划 (已更新)

  * **里程碑 1: 核心契约与新架构验证**

      * **任务**: 定义所有核心抽象 (`ITradingHoursProvider`, `AbstractFetcher` 的模板方法, `IProcessingHandler`)。搭建 `main.py`，**以代码方式**手动组装 `MockFetcher` 和一个由 `ConsoleLogHandler` 构成的简单处理链。
      * **验收**: 运行后，控制台能稳定输出模拟数据，证明 `Fetcher` -\> `Pipeline` 的基础数据流正确。

  * **里程碑 2: 动态市场状态功能**

      * **任务**: 实现 `TradingHoursManager`。创建一个 `MockTradingHoursProvider`，其 `refresh_rules` 方法可以从一个本地文件中读取规则。实现 `/api/v1/market/status/{source_id}` 接口。编写一个定时任务，周期性调用 `refresh_rules`。
      * **验收**: 启动服务，API能返回正确状态。修改本地文件后，等待刷新周期结束，再次调用API能返回更新后的状态。

  * **里程碑 3: 核心处理链与分发逻辑**

      * **任务**: 基于 `MockFetcher`，实现 `KlineConsolidationHandler` 和 `WebhookDispatchHandler`、`SseDispatchHandler`。构建两条独立的处理链，一条用于Webhook，一条用于SSE，并将它们都注册为 `MockFetcher` 的观察者。
      * **验收**: 浏览器连接SSE端点能实时看到数据。同时，在模拟时间的 `xx:15`, `xx:30` 等时刻，`webhook.site` 能收到通知。

  * **里程碑 4: 生产化与健壮性集成**

      * **任务**: 更具项目中 wen_cai模块提供的方法工具，实现一个真实的 `Fetcher` 和一个真实的 `ITradingHoursProvider`（例如，从财经网站上抓取A股和港股的休市安排）。将 `WebhookDispatchHandler` 与 `RetryableTaskExecutor` 和 `DeadLetterQueue` 服务完全集成。
      * **验收**: 系统获取的是真实数据。故意配置无效的Webhook URL，能在日志中看到重试，并最终在DLQ查询接口中看到失败的任务。